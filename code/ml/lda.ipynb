{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66b0aef",
   "metadata": {},
   "source": [
    "# Class Prediction using LDA\n",
    "\n",
    "This script will pre-process, extract features from the recorded dataset. The dataset consists of EMG recordings while the user practices silent and subvocalized speech. For each sample, the user is instructed to \"say\" a word from a vocabulary list, and the sample is labelled with the word. This notebook is used on 3-word datasets, and to evaluate cross-session performance for both the electrode brace, the star array and the control array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7989210a",
   "metadata": {},
   "source": [
    "## Data processing script\n",
    "\n",
    "This step returns a full feature matrix and a class array for training the LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7f536-a135-4fc2-8c3b-ab0cc6dcb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from feature_extractors import window_generator, mav, wl, window_rms\n",
    "from librosa.feature import mfcc, delta, rms\n",
    "\n",
    "# Define configuration\n",
    "INITIALIZATION_WINDOW = [0.5, 4.5] # seconds\n",
    "EMG_SAMPLE_RATE = 250\n",
    "\n",
    "# Window Configuration\n",
    "WINDOW_SIZE = 400 # ms\n",
    "WINDOW_STRIDE = 100 # ms\n",
    "WINDOW_SAMPLE_SIZE = int(EMG_SAMPLE_RATE * (WINDOW_SIZE / 1000)) # should be an integer result\n",
    "WINDOW_SAMPLE_STRIDE = int(EMG_SAMPLE_RATE * (WINDOW_STRIDE / 1000)) # should be an integer result\n",
    "\n",
    "# Define filters\n",
    "sos_notch_50hz = scipy.signal.butter(4, [48,52], 'bandstop', fs=EMG_SAMPLE_RATE, output='sos')\n",
    "sos_highpass = scipy.signal.butter(4, 0.5, 'highpass', fs=EMG_SAMPLE_RATE, output='sos')\n",
    "sos_interest = scipy.signal.butter(4, [2,48], 'bandpass', fs=EMG_SAMPLE_RATE, output='sos')\n",
    "\n",
    "base_path = \"../../datasets/star-50x3-3\"\n",
    "df = pd.read_csv(f\"{base_path}/metadata.csv\")\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # Load in npy from dataset\n",
    "    emg = np.load(f\"{base_path}/{row['id']}.npy\")\n",
    "\n",
    "    # Do basic analog filtering\n",
    "    emg = emg - np.mean(emg, axis=0) # Remove DC\n",
    "    emg = scipy.signal.sosfilt(sos_highpass, emg, axis=0)\n",
    "    emg = scipy.signal.sosfilt(sos_notch_50hz, emg, axis=0)\n",
    "\n",
    "    print(emg.shape)\n",
    "    \n",
    "    # Remove intialization to avoid initialization noise\n",
    "    start = int(INITIALIZATION_WINDOW[0]*EMG_SAMPLE_RATE)\n",
    "    end = int(INITIALIZATION_WINDOW[1]*EMG_SAMPLE_RATE)\n",
    "    emg = emg[start:end,:]\n",
    "\n",
    "    print(emg.shape)\n",
    "\n",
    "    emg_reshaped = np.reshape(emg, (1, emg.shape[0], emg.shape[1])) # is now (1 x TIME x CHANNELS)\n",
    "\n",
    "\n",
    "    mav_features = mav(emg_reshaped)\n",
    "    wl_features = wl(emg_reshaped)\n",
    "    mfcc_features = np.squeeze(mfcc(y=emg.T, sr=EMG_SAMPLE_RATE, n_mfcc=2, n_fft=emg.shape[0], center=False))\n",
    "\n",
    "    # 64 features in total\n",
    "    features = np.vstack((mav_features, wl_features, mfcc_features.T))\n",
    "    # features = np.vstack((mav_features, wl_features, zc_features, ssc_features))\n",
    "    # features = mfcc_features.T\n",
    "    # features = np.vstack((mav_features, zc_features, mfcc_features.T[0:2]))\n",
    "    features = features.ravel()\n",
    "    \n",
    "    if X is None:\n",
    "        X = np.expand_dims(features, axis=0)\n",
    "    else:\n",
    "        X = np.concatenate((X, np.expand_dims(features, axis=0)), axis=0)\n",
    "\n",
    "    if y is None:\n",
    "        y = np.array([row['cls']])\n",
    "    else:\n",
    "        y = np.append(y, row['cls'])\n",
    "\n",
    "print(\"Generated Feature Matrix:\")\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "print(\"Generated Label Matrix:\")\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad1b3a",
   "metadata": {},
   "source": [
    "# Viewing PCA and LDA properties of dataset\n",
    "\n",
    "Setting up PCA and LDA transformations on the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_names = np.unique(y) # Get list of label names\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit(X).transform(X)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", n_components=2)\n",
    "X_lda = lda.fit(X, y).transform(X)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "splot = plt.subplot(1, 2, 1)\n",
    "for color, target_name in zip(['grey', 'mediumpurple', 'blue', 'green', 'yellow', 'orange', 'red', 'sienna'], target_names):\n",
    "    plt.scatter(\n",
    "        X_pca[y == target_name, 0], X_pca[y == target_name, 1], color=color, alpha=0.8, lw=2, label=target_name\n",
    "    )\n",
    "plt.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
    "plt.title(\"PCA of dataset\")\n",
    "plt.tick_params(left = False, right = False , labelleft = False ,\n",
    "                labelbottom = False, bottom = False)\n",
    "\n",
    "splot = plt.subplot(1, 2, 2)\n",
    "for color, target_name in zip(['grey', 'mediumpurple', 'blue', 'green', 'yellow', 'orange', 'red', 'sienna'], target_names):\n",
    "    plt.scatter(\n",
    "        X_lda[y == target_name, 0], X_lda[y == target_name, 1], color=color, alpha=0.8, lw=2, label=target_name\n",
    "    )\n",
    "plt.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
    "plt.title(\"LDA of dataset\")\n",
    "plt.tick_params(left = False, right = False , labelleft = False ,\n",
    "                labelbottom = False, bottom = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a249998",
   "metadata": {},
   "source": [
    "# Linear Discriminator Analysis\n",
    "\n",
    "Setting up K-fold cross validator, across 5 folds for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 39\n",
    "# Include all in test train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=seed)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X[:150,:], y[:150], train_size=0.8) # Session 0 only\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X[150:,:], y[150:], train_size=0.8, random_state=seed) # Session 1 only\n",
    "\n",
    "# X_train = X\n",
    "# y_train = y\n",
    "\n",
    "# Split by session, session 0 for train, session 1 for test\n",
    "#X_train = X[:150,:]\n",
    "#y_train = y[:150]\n",
    "\n",
    "#X_test = X[150:,:]\n",
    "#y_test = y[150:]\n",
    "\n",
    "# Test 0 train 1\n",
    "#X_test = X[:150,:]\n",
    "#y_test = y[:150]\n",
    "\n",
    "#X_train = X[150:,:]\n",
    "#y_train = y[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold, cross_val_score, permutation_test_score, LearningCurveDisplay\n",
    "\n",
    "ss = KFold(n_splits=5)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), LinearDiscriminantAnalysis(solver=\"svd\", n_components=2))\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=ss)\n",
    "score, _, pvalue = permutation_test_score(clf, X_train, y_train, cv=ss)\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f.\" % (scores.mean(), scores.std()))\n",
    "print(\"True score of %0.2f with a pvalue of %0.2f\" % (score, pvalue))\n",
    "\n",
    "LearningCurveDisplay.from_estimator(clf, X_train, y_train, train_sizes=[0.25, 0.50, 0.75, 1.0], cv=ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c02a98",
   "metadata": {},
   "source": [
    "# Sequential feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb0beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential feature selection\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "feature_names = ['mav', 'wl', 'zc', 'ssc', 'mfcc0', 'mfcc1', 'mfcc2', 'mfcc3']\n",
    "\n",
    "feature_names_full = []\n",
    "for i in range(8):\n",
    "    for name in feature_names:\n",
    "        feature_names_full.append(f\"{name}_{i}\")\n",
    "\n",
    "ss = KFold(n_splits=5)\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), LinearDiscriminantAnalysis(solver=\"lsqr\"))\n",
    "\n",
    "\n",
    "sfs_forward = SequentialFeatureSelector(\n",
    "    clf, n_features_to_select=32, direction=\"forward\"\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "sfs_backward = SequentialFeatureSelector(\n",
    "    clf, n_features_to_select=32, direction=\"backward\"\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "features = []\n",
    "print(\"Features selected by forward SFS:\")\n",
    "features.append(sfs_forward.get_feature_names_out(feature_names_full))\n",
    "print(features[0])\n",
    "\n",
    "print(\"Features selected by backward SFS:\")\n",
    "features.append(sfs_backward.get_feature_names_out(feature_names_full))\n",
    "print(features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4fcc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's make a nice pretty plot\n",
    "channel_count = {} # 0 is forward, 1 is backward\n",
    "type_count = {}\n",
    "\n",
    "channels = []\n",
    "types = []\n",
    "channel_groups = {\n",
    "    'forward': [],\n",
    "    'backward': []\n",
    "}\n",
    "type_groups = {\n",
    "    'forward': [],\n",
    "    'backward': []\n",
    "}\n",
    "\n",
    "for i, direction in enumerate(features):\n",
    "    for feature in direction:\n",
    "        type, channel = feature.split(\"_\")\n",
    "\n",
    "        direction = 'forward' if (i == 0) else 'backward'\n",
    "\n",
    "        try:\n",
    "            idx = channels.index(channel)\n",
    "            channel_groups[direction][idx] += 1\n",
    "        except ValueError: # Doesn't have\n",
    "            channels.append(channel)\n",
    "            channel_groups['forward'].append(0)\n",
    "            channel_groups['backward'].append(0)\n",
    "\n",
    "            idx = len(channels) - 1\n",
    "            channel_groups[direction][idx] += 1\n",
    "        \n",
    "        try:\n",
    "            idx = types.index(type)\n",
    "            type_groups[direction][idx] += 1\n",
    "        except ValueError: # Doesn't have\n",
    "            types.append(type)\n",
    "            type_groups['forward'].append(0)\n",
    "            type_groups['backward'].append(0)\n",
    "\n",
    "            idx = len(types) - 1\n",
    "            type_groups[direction][idx] += 1\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "x = np.arange(len(channels))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "for direction, channel_count in channel_groups.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, channel_count, width, label=direction)\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "ax.set_ylabel('Number of times included')\n",
    "ax.set_xlabel('Channel name')\n",
    "\n",
    "ax.set_title('Channel importance from SFS')\n",
    "ax.set_xticks(x + width, channels)\n",
    "ax.legend(loc='upper right', ncols=3)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "x = np.arange(len(types))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "for direction, type_count in type_groups.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, type_count, width, label=direction)\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "ax.set_ylabel('Number of times included')\n",
    "ax.set_xlabel('Type name')\n",
    "\n",
    "ax.set_title('Type importance from SFS')\n",
    "ax.set_xticks(x + width, types)\n",
    "ax.legend(loc='upper right', ncols=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9ad4b",
   "metadata": {},
   "source": [
    "# Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c929ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"The test score is: {score}\")\n",
    "\n",
    "# Let's make a confusion matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
