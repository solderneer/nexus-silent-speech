{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35e799f2",
   "metadata": {},
   "source": [
    "# Hidden Markov Model\n",
    "\n",
    "The notebook to run the HMM on the 30 word dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48e0bc7-aa78-4e11-9baf-0ae13ebc9106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLES PER WINDOW: 100\n",
      "SAMPLES PER STRIDE: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Feature Matrix:\n",
      "(150, 37, 64)\n",
      "Generated Label Matrix:\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import feature_extractors\n",
    "\n",
    "# Define configuration\n",
    "INITIALIZATION_WINDOW = [0.5, 4.5] # seconds\n",
    "EMG_SAMPLE_RATE = 250\n",
    "\n",
    "# Window Configuration\n",
    "WINDOW_SIZE = 400 # ms\n",
    "WINDOW_STRIDE = 100 # ms\n",
    "WINDOW_SAMPLE_SIZE = int(EMG_SAMPLE_RATE * (WINDOW_SIZE / 1000)) # should be an integer result\n",
    "WINDOW_SAMPLE_STRIDE = int(EMG_SAMPLE_RATE * (WINDOW_STRIDE / 1000)) # should be an integer result\n",
    "\n",
    "print(f\"SAMPLES PER WINDOW: {WINDOW_SAMPLE_SIZE}\")\n",
    "print(f\"SAMPLES PER STRIDE: {WINDOW_SAMPLE_STRIDE}\")\n",
    "\n",
    "# Define filters\n",
    "sos_highpass = scipy.signal.butter(4, 0.5, 'highpass', fs=EMG_SAMPLE_RATE, output='sos')\n",
    "sos_notch_50hz = scipy.signal.butter(4, [48,52], 'bandstop', fs=EMG_SAMPLE_RATE, output='sos')\n",
    "\n",
    "base_path = \"../../datasets/electrode-brace/50x3\"\n",
    "df = pd.read_csv(f\"{base_path}/metadata.csv\")\n",
    "\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # Load in npy from dataset\n",
    "    emg = np.load(f\"{base_path}/{row['id']}.npy\")\n",
    "\n",
    "    # Do basic analog filtering\n",
    "    emg = emg - np.mean(emg, axis=0) # Remove DC\n",
    "    emg = scipy.signal.sosfiltfilt(sos_highpass, emg, axis=0, padtype='even')\n",
    "    emg = scipy.signal.sosfiltfilt(sos_notch_50hz, emg, axis=0, padtype='even')\n",
    "\n",
    "    # Remove intialization to avoid initialization noise\n",
    "    emg = emg[int(INITIALIZATION_WINDOW[0]*EMG_SAMPLE_RATE):int(INITIALIZATION_WINDOW[1]*EMG_SAMPLE_RATE),:]\n",
    "    features = feature_extractors.F2(emg, window_size=WINDOW_SAMPLE_SIZE, window_stride=WINDOW_SAMPLE_STRIDE, sr=EMG_SAMPLE_RATE)\n",
    "\n",
    "    if X is None:\n",
    "        X = np.expand_dims(features, axis=0)\n",
    "    else:\n",
    "        X = np.concatenate((X, np.expand_dims(features, axis=0)), axis=0)\n",
    "\n",
    "    if y is None:\n",
    "        y = np.array([row['cls']])\n",
    "    else:\n",
    "        y = np.append(y, row['cls'])\n",
    "\n",
    "print(\"Generated Feature Matrix:\")\n",
    "print(X.shape)\n",
    "\n",
    "print(\"Generated Label Matrix:\")\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be55ec22-ce5c-429e-9fe1-9d7b407b1593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 37, 64)\n",
      "(30, 37, 64)\n",
      "(120,)\n",
      "(30,)\n",
      "['air' 'bat' 'cap']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Seed for reproducible pseudo-randomness\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "split = 0\n",
    "\n",
    "if split == 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "elif split == 1:\n",
    "    X_train = X\n",
    "    X_test = X\n",
    "    y_train = y\n",
    "    y_test = y\n",
    "elif split == 2:\n",
    "    X_train = X[:443]\n",
    "    X_test = X[443:]\n",
    "    y_train = y[:443]\n",
    "    y_test = y[443:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "y_labels = le.transform(y)\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd03eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4440, 64)\n",
      "(120, 37, 2)\n",
      "(30, 37, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from joblib import dump, load\n",
    "\n",
    "N_COMPONENTS = 2\n",
    "\n",
    "# Train an LDA\n",
    "X_train_LDA = np.reshape(X_train, (-1, X_train.shape[2])) # Flatten frames\n",
    "X_test_LDA = np.reshape(X_test, (-1, X_test.shape[2]))\n",
    "\n",
    "print(X_train_LDA.shape)\n",
    "\n",
    "y_train_LDA = np.repeat(y_train, X.shape[1])\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=N_COMPONENTS)\n",
    "X_train_LDA = lda.fit(X_train_LDA, y_train_LDA).transform(X_train_LDA)\n",
    "\n",
    "X_test_LDA = lda.transform(X_test_LDA)\n",
    "\n",
    "dump(lda, '../demo/lda.joblib')\n",
    "# dump(lda, 'lda.joblib')\n",
    "\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#X_norm = scaler.fit(X_LDA).transform(X_LDA)\n",
    "\n",
    "X_train = np.reshape(X_train_LDA, (X_train.shape[0], X_train.shape[1], -1)) # Unflatten frames\n",
    "X_test = np.reshape(X_test_LDA, (X_test.shape[0], X_test.shape[1], -1)) # Unflatten frames\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23516e3b-650f-497d-ab09-e516e6ccf461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(40, 37, 2)\n",
      "-3661.837089962355\n",
      "-3659.5766433424624\n",
      "-3800.1192251029224\n",
      "-3811.6694301297243\n",
      "-3659.5774812346563\n",
      "1\n",
      "(40, 37, 2)\n",
      "-3928.0664515429567\n",
      "-3928.065415297674\n",
      "-3688.9335129353053\n",
      "-3957.8534681331344\n",
      "-3957.8536662114907\n",
      "2\n",
      "(40, 37, 2)\n",
      "-3278.581542864605\n",
      "-3419.853954164098\n",
      "-3295.140916077182\n",
      "-3419.8539129009337\n",
      "-3295.141045167137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../demo/hmm_models.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "\n",
    "def make_ltr_transition(n):\n",
    "    transmat = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        if i == (n - 1):\n",
    "            transmat[i,i] = 1.0\n",
    "        else:\n",
    "            transmat[i,i] = 0.5\n",
    "            transmat[i, i+1] = 0.5\n",
    "    return transmat\n",
    "\n",
    "def get_model(X, lengths, states=3, n_iter=5):\n",
    "    best_model = None\n",
    "    best_ll = None\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        model = hmm.GaussianHMM(n_components=states, covariance_type=\"diag\", n_iter=100, init_params='c', params='cmt')\n",
    "    \n",
    "        startprob = np.zeros(states)\n",
    "        startprob[0] = 1.0\n",
    "        model.startprob_ = startprob\n",
    "    \n",
    "        model.transmat_ = make_ltr_transition(states)\n",
    "        try:\n",
    "            model.fit(X, lengths)\n",
    "            score = model.score(X, lengths)\n",
    "        except:\n",
    "            continue\n",
    "        print(score)\n",
    "        if not best_ll or best_ll < score:\n",
    "            best_ll = score\n",
    "            best_model = model\n",
    "\n",
    "    return best_model\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    mask = (y_train == i)\n",
    "    X_mask = X_train[mask]\n",
    "    \n",
    "    lengths = [len(x) for x in X_mask]\n",
    "    X_mask_flat = np.reshape(X_mask, (-1, X_mask.shape[2]))\n",
    "\n",
    "    print(i)\n",
    "    print(X_mask.shape)\n",
    "    model = get_model(X_mask_flat, lengths)\n",
    "    models.append(model)\n",
    "\n",
    "# dump(models, 'hmm_models.joblib')\n",
    "dump(models, '../demo/hmm_models.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b0201d-efd0-4d8b-8c19-59cbe64394d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 == 0\n",
      "2 == 2\n",
      "2 == 1\n",
      "2 == 1\n",
      "0 == 0\n",
      "1 == 1\n",
      "2 == 0\n",
      "0 == 0\n",
      "2 == 2\n",
      "1 == 1\n",
      "1 == 2\n",
      "2 == 2\n",
      "2 == 2\n",
      "0 == 1\n",
      "0 == 0\n",
      "2 == 0\n",
      "0 == 0\n",
      "1 == 1\n",
      "1 == 1\n",
      "2 == 2\n",
      "0 == 0\n",
      "2 == 2\n",
      "1 == 1\n",
      "0 == 2\n",
      "0 == 2\n",
      "1 == 1\n",
      "1 == 1\n",
      "0 == 0\n",
      "1 == 2\n",
      "1 == 0\n",
      "0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "X_acc = X_test\n",
    "y_acc = y_test\n",
    "\n",
    "for index, x in enumerate(X_acc):\n",
    "    best_ll = None\n",
    "    best_class = None\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        score = model.score(x)\n",
    "        if not best_ll or best_ll < score:\n",
    "            best_ll = score\n",
    "            best_class = i\n",
    "\n",
    "    print(f\"{best_class} == {y_acc[index]}\")\n",
    "    if y_acc[index] == best_class:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
